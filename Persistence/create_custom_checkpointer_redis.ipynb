{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following packages are already present in the pyproject.toml and will be skipped:\n",
      "\n",
      "  - \u001b[36mredis\u001b[39m\n",
      "\n",
      "If you want to update it to the latest compatible version, you can use `poetry update package`.\n",
      "If you prefer to upgrade it to the latest available version, you can use `poetry add package@latest`.\n",
      "\n",
      "Nothing to add.\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "#%pip install -U redis langgraph\n",
    "#!poetry add redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation of a langgraph checkpoint saver using Redis.\"\"\"\n",
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from typing import Any, AsyncGenerator, Generator, Union, Tuple, Optional\n",
    "\n",
    "import redis\n",
    "from redis.asyncio import Redis as AsyncRedis, ConnectionPool as AsyncConnectionPool\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint import BaseCheckpointSaver\n",
    "from langgraph.serde.jsonplus import JsonPlusSerializer\n",
    "from langgraph.checkpoint.base import Checkpoint, CheckpointMetadata, CheckpointTuple\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class JsonAndBinarySerializer(JsonPlusSerializer):\n",
    "    def _default(self, obj: Any) -> Any:\n",
    "        if isinstance(obj, (bytes, bytearray)):\n",
    "            return self._encode_constructor_args(obj.__class__, method=\"fromhex\", args=[obj.hex()])\n",
    "        return super()._default(obj)\n",
    "\n",
    "    def dumps(self, obj: Any) -> str:\n",
    "        try:\n",
    "            if isinstance(obj, (bytes, bytearray)):\n",
    "                return obj.hex()\n",
    "            return super().dumps(obj)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Serialization error: {e}\")\n",
    "            raise\n",
    "\n",
    "    def loads(self, s: str, is_binary: bool = False) -> Any:\n",
    "        try:\n",
    "            if is_binary:\n",
    "                return bytes.fromhex(s)\n",
    "            return super().loads(s)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Deserialization error: {e}\")\n",
    "            raise\n",
    "\n",
    "def initialize_sync_pool(host: str = 'localhost', port: int = 6379, db: int = 0, **kwargs) -> redis.ConnectionPool:\n",
    "    \"\"\"Initialize a synchronous Redis connection pool.\"\"\"\n",
    "    try:\n",
    "        pool = redis.ConnectionPool(host=host, port=port, db=db, **kwargs)\n",
    "        logger.info(f\"Synchronous Redis pool initialized with host={host}, port={port}, db={db}\")\n",
    "        return pool\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing sync pool: {e}\")\n",
    "        raise\n",
    "\n",
    "def initialize_async_pool(url: str = \"redis://localhost\", **kwargs) -> AsyncConnectionPool:\n",
    "    \"\"\"Initialize an asynchronous Redis connection pool.\"\"\"\n",
    "    try:\n",
    "        pool = AsyncConnectionPool.from_url(url, **kwargs)\n",
    "        logger.info(f\"Asynchronous Redis pool initialized with url={url}\")\n",
    "        return pool\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error initializing async pool: {e}\")\n",
    "        raise\n",
    "\n",
    "@contextmanager\n",
    "def _get_sync_connection(connection: Union[redis.Redis, redis.ConnectionPool, None]) -> Generator[redis.Redis, None, None]:\n",
    "    conn = None\n",
    "    try:\n",
    "        if isinstance(connection, redis.Redis):\n",
    "            yield connection\n",
    "        elif isinstance(connection, redis.ConnectionPool):\n",
    "            conn = redis.Redis(connection_pool=connection)\n",
    "            yield conn\n",
    "        else:\n",
    "            raise ValueError(\"Invalid sync connection object.\")\n",
    "    except redis.ConnectionError as e:\n",
    "        logger.error(f\"Sync connection error: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "@asynccontextmanager\n",
    "async def _get_async_connection(connection: Union[AsyncRedis, AsyncConnectionPool, None]) -> AsyncGenerator[AsyncRedis, None]:\n",
    "    conn = None\n",
    "    try:\n",
    "        if isinstance(connection, AsyncRedis):\n",
    "            yield connection\n",
    "        elif isinstance(connection, AsyncConnectionPool):\n",
    "            conn = AsyncRedis(connection_pool=connection)\n",
    "            yield conn\n",
    "        else:\n",
    "            raise ValueError(\"Invalid async connection object.\")\n",
    "    except redis.ConnectionError as e:\n",
    "        logger.error(f\"Async connection error: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if conn:\n",
    "            await conn.aclose()\n",
    "\n",
    "class RedisSaver(BaseCheckpointSaver):\n",
    "    sync_connection: Optional[Union[redis.Redis, redis.ConnectionPool]] = None\n",
    "    async_connection: Optional[Union[AsyncRedis, AsyncConnectionPool]] = None\n",
    "\n",
    "    def __init__(self, sync_connection: Optional[Union[redis.Redis, redis.ConnectionPool]] = None, async_connection: Optional[Union[AsyncRedis, AsyncConnectionPool]] = None):\n",
    "        super().__init__(serde=JsonAndBinarySerializer())\n",
    "        self.sync_connection = sync_connection\n",
    "        self.async_connection = async_connection\n",
    "\n",
    "    def put(self, config: RunnableConfig, checkpoint: Checkpoint, metadata: CheckpointMetadata) -> RunnableConfig:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        key = f\"checkpoint:{thread_id}:{checkpoint['ts']}\"\n",
    "        try:\n",
    "            with _get_sync_connection(self.sync_connection) as conn:\n",
    "                conn.hset(key, mapping={\n",
    "                    \"checkpoint\": self.serde.dumps(checkpoint),\n",
    "                    \"metadata\": self.serde.dumps(metadata),\n",
    "                    \"parent_ts\": parent_ts if parent_ts else \"\"\n",
    "                })\n",
    "                logger.info(f\"Checkpoint stored successfully for thread_id: {thread_id}, ts: {checkpoint['ts']}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to put checkpoint: {e}\")\n",
    "            raise\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": checkpoint[\"ts\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    async def aput(self, config: RunnableConfig, checkpoint: Checkpoint, metadata: CheckpointMetadata) -> RunnableConfig:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        key = f\"checkpoint:{thread_id}:{checkpoint['ts']}\"\n",
    "        try:\n",
    "            async with _get_async_connection(self.async_connection) as conn:\n",
    "                await conn.hset(key, mapping={\n",
    "                    \"checkpoint\": self.serde.dumps(checkpoint),\n",
    "                    \"metadata\": self.serde.dumps(metadata),\n",
    "                    \"parent_ts\": parent_ts if parent_ts else \"\"\n",
    "                })\n",
    "                logger.info(f\"Checkpoint stored successfully for thread_id: {thread_id}, ts: {checkpoint['ts']}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to aput checkpoint: {e}\")\n",
    "            raise\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": checkpoint[\"ts\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\"thread_ts\", None)\n",
    "        try:\n",
    "            with _get_sync_connection(self.sync_connection) as conn:\n",
    "                if thread_ts:\n",
    "                    key = f\"checkpoint:{thread_id}:{thread_ts}\"\n",
    "                else:\n",
    "                    all_keys = conn.keys(f\"checkpoint:{thread_id}:*\")\n",
    "                    if not all_keys:\n",
    "                        logger.info(f\"No checkpoints found for thread_id: {thread_id}\")\n",
    "                        return None\n",
    "                    latest_key = max(all_keys, key=lambda k: k.decode().split(\":\")[-1])\n",
    "                    key = latest_key.decode()\n",
    "                checkpoint_data = conn.hgetall(key)\n",
    "                if not checkpoint_data:\n",
    "                    logger.info(f\"No valid checkpoint data found for key: {key}\")\n",
    "                    return None\n",
    "                checkpoint = self.serde.loads(checkpoint_data[b\"checkpoint\"].decode())\n",
    "                metadata = self.serde.loads(checkpoint_data[b\"metadata\"].decode())\n",
    "                parent_ts = checkpoint_data.get(b\"parent_ts\", b\"\").decode()\n",
    "                parent_config = {\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": parent_ts}} if parent_ts else None\n",
    "                logger.info(f\"Checkpoint retrieved successfully for thread_id: {thread_id}, ts: {thread_ts}\")\n",
    "                return CheckpointTuple(config=config, checkpoint=checkpoint, metadata=metadata, parent_config=parent_config)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to get checkpoint tuple: {e}\")\n",
    "            raise\n",
    "\n",
    "    async def aget_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\"thread_ts\", None)\n",
    "        try:\n",
    "            async with _get_async_connection(self.async_connection) as conn:\n",
    "                if thread_ts:\n",
    "                    key = f\"checkpoint:{thread_id}:{thread_ts}\"\n",
    "                else:\n",
    "                    all_keys = await conn.keys(f\"checkpoint:{thread_id}:*\")\n",
    "                    if not all_keys:\n",
    "                        logger.info(f\"No checkpoints found for thread_id: {thread_id}\")\n",
    "                        return None\n",
    "                    latest_key = max(all_keys, key=lambda k: k.decode().split(\":\")[-1])\n",
    "                    key = latest_key.decode()\n",
    "                checkpoint_data = await conn.hgetall(key)\n",
    "                if not checkpoint_data:\n",
    "                    logger.info(f\"No valid checkpoint data found for key: {key}\")\n",
    "                    return None\n",
    "                checkpoint = self.serde.loads(checkpoint_data[b\"checkpoint\"].decode())\n",
    "                metadata = self.serde.loads(checkpoint_data[b\"metadata\"].decode())\n",
    "                parent_ts = checkpoint_data.get(b\"parent_ts\", b\"\").decode()\n",
    "                parent_config = {\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": parent_ts}} if parent_ts else None\n",
    "                logger.info(f\"Checkpoint retrieved successfully for thread_id: {thread_id}, ts: {thread_ts}\")\n",
    "                return CheckpointTuple(config=config, checkpoint=checkpoint, metadata=metadata, parent_config=parent_config)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to get checkpoint tuple: {e}\")\n",
    "            raise\n",
    "\n",
    "    def list(self, config: Optional[RunnableConfig], *, filter: Optional[dict[str, Any]] = None, before: Optional[RunnableConfig] = None, limit: Optional[int] = None) -> Generator[CheckpointTuple, None, None]:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"] if config else \"*\"\n",
    "        pattern = f\"checkpoint:{thread_id}:*\"\n",
    "        try:\n",
    "            with _get_sync_connection(self.sync_connection) as conn:\n",
    "                keys = conn.keys(pattern)\n",
    "                if before:\n",
    "                    keys = [k for k in keys if k.decode().split(\":\")[-1] < before[\"configurable\"][\"thread_ts\"]]\n",
    "                keys = sorted(keys, key=lambda k: k.decode().split(\":\")[-1], reverse=True)\n",
    "                if limit:\n",
    "                    keys = keys[:limit]\n",
    "                for key in keys:\n",
    "                    data = conn.hgetall(key)\n",
    "                    if data and \"checkpoint\" in data and \"metadata\" in data:\n",
    "                        thread_ts = key.decode().split(\":\")[-1]\n",
    "                        yield CheckpointTuple(\n",
    "                            config={\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": thread_ts}},\n",
    "                            checkpoint=self.serde.loads(data[\"checkpoint\"].decode()),\n",
    "                            metadata=self.serde.loads(data[\"metadata\"].decode()),\n",
    "                            parent_config={\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": data.get(\"parent_ts\", b\"\").decode()}} if data.get(\"parent_ts\") else None,\n",
    "                        )\n",
    "                        logger.info(f\"Checkpoint listed for thread_id: {thread_id}, ts: {thread_ts}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to list checkpoints: {e}\")\n",
    "            raise\n",
    "\n",
    "    async def alist(self, config: Optional[RunnableConfig], *, filter: Optional[dict[str, Any]] = None, before: Optional[RunnableConfig] = None, limit: Optional[int] = None) -> AsyncGenerator[CheckpointTuple, None]:\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"] if config else \"*\"\n",
    "        pattern = f\"checkpoint:{thread_id}:*\"\n",
    "        try:\n",
    "            async with _get_async_connection(self.async_connection) as conn:\n",
    "                keys = await conn.keys(pattern)\n",
    "                if before:\n",
    "                    keys = [k for k in keys if k.decode().split(\":\")[-1] < before[\"configurable\"][\"thread_ts\"]]\n",
    "                keys = sorted(keys, key=lambda k: k.decode().split(\":\")[-1], reverse=True)\n",
    "                if limit:\n",
    "                    keys = keys[:limit]\n",
    "                for key in keys:\n",
    "                    data = await conn.hgetall(key)\n",
    "                    if data and \"checkpoint\" in data and \"metadata\" in data:\n",
    "                        thread_ts = key.decode().split(\":\")[-1]\n",
    "                        yield CheckpointTuple(\n",
    "                            config={\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": thread_ts}},\n",
    "                            checkpoint=self.serde.loads(data[\"checkpoint\"].decode()),\n",
    "                            metadata=self.serde.loads(data[\"metadata\"].decode()),\n",
    "                            parent_config={\"configurable\": {\"thread_id\": thread_id, \"thread_ts\": data.get(\"parent_ts\", b\"\").decode()}} if data.get(\"parent_ts\") else None,\n",
    "                        )\n",
    "                        logger.info(f\"Checkpoint listed for thread_id: {thread_id}, ts: {thread_ts}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to list checkpoints: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../envls')\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Synchronous Redis pool initialized with host=192.168.10.111, port=6379, db=0\n"
     ]
    }
   ],
   "source": [
    "sync_pool = initialize_sync_pool(host=\"192.168.10.111\", port=6379, db=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = RedisSaver(sync_connection=sync_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:No checkpoints found for thread_id: 1\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 1, ts: 2024-07-18T11:00:06.770344+00:00\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 1, ts: 2024-07-18T11:00:06.772860+00:00\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 1, ts: 2024-07-18T11:00:08.035649+00:00\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 1, ts: 2024-07-18T11:00:08.040913+00:00\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 1, ts: 2024-07-18T11:00:09.024135+00:00\n"
     ]
    }
   ],
   "source": [
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's the weather in sf\", id='f37994f4-1d69-4732-8d7a-a5c6a46fbbe8'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_etUo4j1w943DDQnc43Xbfsnw', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-104a2b3d-39d0-42a7-8212-5b11188f5801-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_etUo4j1w943DDQnc43Xbfsnw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),\n",
       "  ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='e2a70946-0a6a-45f3-8a99-8cb625632495', tool_call_id='call_etUo4j1w943DDQnc43Xbfsnw'),\n",
       "  AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-873dd373-2711-4b76-9c1c-d233c7f03ad0-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Checkpoint retrieved successfully for thread_id: 1, ts: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'v': 1,\n",
       " 'ts': '2024-07-18T11:00:08.035649+00:00',\n",
       " 'id': '1ef44f4e-53b5-6cfd-8001-fe2c358079d1',\n",
       " 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='f37994f4-1d69-4732-8d7a-a5c6a46fbbe8'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_etUo4j1w943DDQnc43Xbfsnw', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-104a2b3d-39d0-42a7-8212-5b11188f5801-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_etUo4j1w943DDQnc43Xbfsnw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71})],\n",
       "  'agent': 'agent',\n",
       "  'branch:agent:should_continue:tools': 'agent'},\n",
       " 'channel_versions': {'__start__': 2,\n",
       "  'messages': 3,\n",
       "  'start:agent': 3,\n",
       "  'agent': 3,\n",
       "  'branch:agent:should_continue:tools': 3},\n",
       " 'versions_seen': {'__start__': {'__start__': 1},\n",
       "  'agent': {'start:agent': 2},\n",
       "  'tools': {}},\n",
       " 'pending_sends': []}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer.get(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:No checkpoints found for thread_id: 2\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 2, ts: 2024-07-18T11:02:50.951362+00:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Checkpoint stored successfully for thread_id: 2, ts: 2024-07-18T11:02:50.953083+00:00\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 2, ts: 2024-07-18T11:02:52.091451+00:00\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 2, ts: 2024-07-18T11:02:52.095902+00:00\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 2, ts: 2024-07-18T11:02:53.251495+00:00\n",
      "INFO:__main__:Checkpoint retrieved successfully for thread_id: 2, ts: None\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "\n",
    "# Initialize the Redis synchronous direct connection\n",
    "sync_redis_direct = redis.Redis(host='192.168.10.111', port=6379, db=0)\n",
    "\n",
    "# Initialize the RedisSaver with the synchronous direct connection\n",
    "checkpointer = RedisSaver(sync_connection=sync_redis_direct)\n",
    "\n",
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)\n",
    "\n",
    "checkpoint_tuple = checkpointer.get_tuple(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Asynchronous Redis pool initialized with url=redis://192.168.10.111:6379/0\n"
     ]
    }
   ],
   "source": [
    "# Initialize a synchronous Redis connection pool\n",
    "async_pool = initialize_async_pool(url='redis://192.168.10.111:6379/0')\n",
    "\n",
    "checkpointer = RedisSaver(async_connection=async_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:No checkpoints found for thread_id: 3\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 3, ts: 2024-07-18T11:03:02.597488+00:00\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 3, ts: 2024-07-18T11:03:02.599408+00:00\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 3, ts: 2024-07-18T11:03:03.441296+00:00\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 3, ts: 2024-07-18T11:03:03.437808+00:00\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 3, ts: 2024-07-18T11:03:04.406769+00:00\n"
     ]
    }
   ],
   "source": [
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "res = await graph.ainvoke(\n",
    "    {\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Checkpoint retrieved successfully for thread_id: 3, ts: None\n"
     ]
    }
   ],
   "source": [
    "checkpoint_tuple = await checkpointer.aget_tuple(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CheckpointTuple(config={'configurable': {'thread_id': '3'}}, checkpoint={'v': 1, 'ts': '2024-07-18T11:03:02.597488+00:00', 'id': '1ef44f54-d476-62ce-bfff-1e1326af3759', 'channel_values': {'messages': [], '__start__': {'messages': [['human', \"what's the weather in nyc\"]]}}, 'channel_versions': {'__start__': 1}, 'versions_seen': {}, 'pending_sends': []}, metadata={'source': 'input', 'step': -1, 'writes': {'messages': [['human', \"what's the weather in nyc\"]]}}, parent_config=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:No checkpoints found for thread_id: 4\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 4, ts: 2024-07-18T11:03:08.942458+00:00\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 4, ts: 2024-07-18T11:03:08.944280+00:00\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 4, ts: 2024-07-18T11:03:09.777289+00:00\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 4, ts: 2024-07-18T11:03:09.773785+00:00\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:__main__:Checkpoint stored successfully for thread_id: 4, ts: 2024-07-18T11:03:10.606230+00:00\n"
     ]
    }
   ],
   "source": [
    "from redis.asyncio import Redis as AsyncRedis\n",
    "\n",
    "async with await AsyncRedis(host='192.168.10.111', port=6379, db=0) as conn:\n",
    "    checkpointer = RedisSaver(async_connection=conn)\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "    res = await graph.ainvoke(\n",
    "        {\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config\n",
    "    )\n",
    "    checkpoint_tuples = [c async for c in checkpointer.alist(config)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langserve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
