{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BaseCheckpointSaver interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "#%pip install -U psycopg psycopg-pool langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Implementation of a langgraph checkpoint saver using Postgres.\"\"\"\n",
    "from contextlib import asynccontextmanager, contextmanager\n",
    "from typing import (\n",
    "    Any,\n",
    "    AsyncGenerator,\n",
    "    AsyncIterator,\n",
    "    Generator,\n",
    "    Optional,\n",
    "    Union,\n",
    "    Tuple,\n",
    "    List,\n",
    "    Sequence\n",
    ")\n",
    "\n",
    "import psycopg\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.checkpoint import BaseCheckpointSaver\n",
    "from langgraph.serde.jsonplus import JsonPlusSerializer\n",
    "from langgraph.checkpoint.base import Checkpoint, CheckpointMetadata, CheckpointTuple\n",
    "from psycopg_pool import AsyncConnectionPool, ConnectionPool\n",
    "\n",
    "\n",
    "class JsonAndBinarySerializer(JsonPlusSerializer):\n",
    "    def _default(self, obj):\n",
    "        if isinstance(obj, (bytes, bytearray)):\n",
    "            return self._encode_constructor_args(\n",
    "                obj.__class__, method=\"fromhex\", args=[obj.hex()]\n",
    "            )\n",
    "        return super()._default(obj)\n",
    "\n",
    "    def dumps(self, obj: Any) -> tuple[str, bytes]:\n",
    "        if isinstance(obj, bytes):\n",
    "            return \"bytes\", obj\n",
    "        elif isinstance(obj, bytearray):\n",
    "            return \"bytearray\", obj\n",
    "\n",
    "        return \"json\", super().dumps(obj)\n",
    "\n",
    "    def loads(self, s: tuple[str, bytes]) -> Any:\n",
    "        if s[0] == \"bytes\":\n",
    "            return s[1]\n",
    "        elif s[0] == \"bytearray\":\n",
    "            return bytearray(s[1])\n",
    "        elif s[0] == \"json\":\n",
    "            return super().loads(s[1])\n",
    "        else:\n",
    "            raise NotImplementedError(f\"Unknown serialization type: {s[0]}\")\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def _get_sync_connection(\n",
    "    connection: Union[psycopg.Connection, ConnectionPool, None],\n",
    ") -> Generator[psycopg.Connection, None, None]:\n",
    "    \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "    if isinstance(connection, psycopg.Connection):\n",
    "        yield connection\n",
    "    elif isinstance(connection, ConnectionPool):\n",
    "        with connection.connection() as conn:\n",
    "            yield conn\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid sync connection object. Please initialize the check pointer \"\n",
    "            f\"with an appropriate sync connection object. \"\n",
    "            f\"Got {type(connection)}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def _get_async_connection(\n",
    "    connection: Union[psycopg.AsyncConnection, AsyncConnectionPool, None],\n",
    ") -> AsyncGenerator[psycopg.AsyncConnection, None]:\n",
    "    \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "    if isinstance(connection, psycopg.AsyncConnection):\n",
    "        yield connection\n",
    "    elif isinstance(connection, AsyncConnectionPool):\n",
    "        async with connection.connection() as conn:\n",
    "            yield conn\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Invalid async connection object. Please initialize the check pointer \"\n",
    "            f\"with an appropriate async connection object. \"\n",
    "            f\"Got {type(connection)}.\"\n",
    "        )\n",
    "\n",
    "\n",
    "class PostgresSaver(BaseCheckpointSaver):\n",
    "    sync_connection: Optional[Union[psycopg.Connection, ConnectionPool]] = None\n",
    "    \"\"\"The synchronous connection or pool to the Postgres database.\n",
    "\n",
    "    If providing a connection object, please ensure that the connection is open\n",
    "    and remember to close the connection when done.\n",
    "    \"\"\"\n",
    "    async_connection: Optional[\n",
    "        Union[psycopg.AsyncConnection, AsyncConnectionPool]\n",
    "    ] = None\n",
    "    \"\"\"The asynchronous connection or pool to the Postgres database.\n",
    "\n",
    "    If providing a connection object, please ensure that the connection is open\n",
    "    and remember to close the connection when done.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sync_connection: Optional[Union[psycopg.Connection, ConnectionPool]] = None,\n",
    "        async_connection: Optional[\n",
    "            Union[psycopg.AsyncConnection, AsyncConnectionPool]\n",
    "        ] = None,\n",
    "    ):\n",
    "        super().__init__(serde=JsonPlusSerializer())\n",
    "        self.sync_connection = sync_connection\n",
    "        self.async_connection = async_connection\n",
    "\n",
    "    @contextmanager\n",
    "    def _get_sync_connection(self) -> Generator[psycopg.Connection, None, None]:\n",
    "        \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "        with _get_sync_connection(self.sync_connection) as connection:\n",
    "            yield connection\n",
    "\n",
    "    @asynccontextmanager\n",
    "    async def _get_async_connection(\n",
    "        self,\n",
    "    ) -> AsyncGenerator[psycopg.AsyncConnection, None]:\n",
    "        \"\"\"Get the connection to the Postgres database.\"\"\"\n",
    "        async with _get_async_connection(self.async_connection) as connection:\n",
    "            yield connection\n",
    "\n",
    "    CREATE_TABLES_QUERY = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS checkpoints (\n",
    "        thread_id TEXT NOT NULL,\n",
    "        thread_ts TEXT NOT NULL,\n",
    "        parent_ts TEXT,\n",
    "        checkpoint BYTEA NOT NULL,\n",
    "        metadata BYTEA NOT NULL,\n",
    "        PRIMARY KEY (thread_id, thread_ts)\n",
    "    );\n",
    "    CREATE TABLE IF NOT EXISTS writes (\n",
    "        thread_id TEXT NOT NULL,\n",
    "        thread_ts TEXT NOT NULL,\n",
    "        task_id TEXT NOT NULL,\n",
    "        idx INTEGER NOT NULL,\n",
    "        channel TEXT NOT NULL,\n",
    "        value BYTEA,\n",
    "        PRIMARY KEY (thread_id, thread_ts, task_id, idx)\n",
    "    );\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def create_tables(connection: Union[psycopg.Connection, ConnectionPool], /) -> None:\n",
    "        \"\"\"Create the schema for the checkpoint saver.\"\"\"\n",
    "        with _get_sync_connection(connection) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(PostgresSaver.CREATE_TABLES_QUERY)\n",
    "\n",
    "    @staticmethod\n",
    "    async def acreate_tables(\n",
    "        connection: Union[psycopg.AsyncConnection, AsyncConnectionPool], /\n",
    "    ) -> None:\n",
    "        \"\"\"Create the schema for the checkpoint saver.\"\"\"\n",
    "        async with _get_async_connection(connection) as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.execute(PostgresSaver.CREATE_TABLES_QUERY)\n",
    "\n",
    "    @staticmethod\n",
    "    def drop_tables(connection: psycopg.Connection, /) -> None:\n",
    "        \"\"\"Drop the table for the checkpoint saver.\"\"\"\n",
    "        with connection.cursor() as cur:\n",
    "            cur.execute(\"DROP TABLE IF EXISTS checkpoints, writes;\")\n",
    "\n",
    "    @staticmethod\n",
    "    async def adrop_tables(connection: psycopg.AsyncConnection, /) -> None:\n",
    "        \"\"\"Drop the table for the checkpoint saver.\"\"\"\n",
    "        async with connection.cursor() as cur:\n",
    "            await cur.execute(\"DROP TABLE IF EXISTS checkpoints, writes;\")\n",
    "\n",
    "    UPSERT_CHECKPOINT_QUERY = \"\"\"\n",
    "    INSERT INTO checkpoints\n",
    "        (thread_id, thread_ts, parent_ts, checkpoint, metadata)\n",
    "    VALUES\n",
    "        (%s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (thread_id, thread_ts)\n",
    "    DO UPDATE SET checkpoint = EXCLUDED.checkpoint,\n",
    "                  metadata = EXCLUDED.metadata;\n",
    "    \"\"\"\n",
    "\n",
    "    def put(\n",
    "        self,\n",
    "        config: RunnableConfig,\n",
    "        checkpoint: Checkpoint,\n",
    "        metadata: CheckpointMetadata,\n",
    "    ) -> RunnableConfig:\n",
    "        \"\"\"Put the checkpoint for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "            checkpoint: The checkpoint to persist.\n",
    "        Returns:\n",
    "            The RunnableConfig that describes the checkpoint that was just created.\n",
    "            It'll contain the `thread_id` and `thread_ts` of the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.execute(\n",
    "                    self.UPSERT_CHECKPOINT_QUERY,\n",
    "                    (\n",
    "                        thread_id,\n",
    "                        checkpoint[\"id\"],\n",
    "                        parent_ts if parent_ts else None,\n",
    "                        self.serde.dumps(checkpoint),\n",
    "                        self.serde.dumps(metadata),\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": checkpoint[\"id\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    async def aput(\n",
    "        self,\n",
    "        config: RunnableConfig,\n",
    "        checkpoint: Checkpoint,\n",
    "        metadata: CheckpointMetadata,\n",
    "    ) -> RunnableConfig:\n",
    "        \"\"\"Put the checkpoint for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "            checkpoint: The checkpoint to persist.\n",
    "        Returns:\n",
    "            The RunnableConfig that describes the checkpoint that was just created.\n",
    "            It'll contain the `thread_id` and `thread_ts` of the checkpoint.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        parent_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.execute(\n",
    "                    self.UPSERT_CHECKPOINT_QUERY,\n",
    "                    (\n",
    "                        thread_id,\n",
    "                        checkpoint[\"id\"],\n",
    "                        parent_ts if parent_ts else None,\n",
    "                        self.serde.dumps(checkpoint),\n",
    "                        self.serde.dumps(metadata),\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "        return {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"thread_ts\": checkpoint[\"id\"],\n",
    "            },\n",
    "        }\n",
    "\n",
    "    UPSERT_WRITES_QUERY = \"\"\"\n",
    "    INSERT INTO writes\n",
    "        (thread_id, thread_ts, task_id, idx, channel, value)\n",
    "    VALUES\n",
    "        (%s, %s, %s, %s, %s, %s)\n",
    "    ON CONFLICT (thread_id, thread_ts, task_id, idx)\n",
    "    DO UPDATE SET value = EXCLUDED.value;\n",
    "    \"\"\"\n",
    "\n",
    "    def put_writes(\n",
    "        self,\n",
    "        config: RunnableConfig,\n",
    "        writes: Sequence[Tuple[str, Any]],\n",
    "        task_id: str,\n",
    "    ) -> None:\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                cur.executemany(\n",
    "                    self.UPSERT_WRITES_QUERY,\n",
    "                    [\n",
    "                        (\n",
    "                            str(config[\"configurable\"][\"thread_id\"]),\n",
    "                            str(config[\"configurable\"][\"thread_ts\"]),\n",
    "                            task_id,\n",
    "                            idx,\n",
    "                            channel,\n",
    "                            self.serde.dumps(value),\n",
    "                        )\n",
    "                        for idx, (channel, value) in enumerate(writes)\n",
    "                    ],\n",
    "                )\n",
    "            conn.commit()\n",
    "\n",
    "    async def aput_writes(\n",
    "        self,\n",
    "        config: RunnableConfig,\n",
    "        writes: Sequence[Tuple[str, Any]],\n",
    "        task_id: str,\n",
    "    ) -> None:\n",
    "\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                await cur.executemany(\n",
    "                    self.UPSERT_WRITES_QUERY,\n",
    "                    [\n",
    "                        (\n",
    "                            str(config[\"configurable\"][\"thread_id\"]),\n",
    "                            str(config[\"configurable\"][\"thread_ts\"]),\n",
    "                            task_id,\n",
    "                            idx,\n",
    "                            channel,\n",
    "                            self.serde.dumps(value),\n",
    "                        )\n",
    "                        for idx, (channel, value) in enumerate(writes)\n",
    "                    ],\n",
    "                )\n",
    "            await conn.commit()\n",
    "\n",
    "    LIST_CHECKPOINTS_QUERY_STR = \"\"\"\n",
    "    SELECT checkpoint, metadata, thread_ts, parent_ts\n",
    "    FROM checkpoints\n",
    "    {where}\n",
    "    ORDER BY thread_ts DESC\n",
    "    \"\"\"\n",
    "\n",
    "    def list(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        *,\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> Generator[CheckpointTuple, None, None]:\n",
    "        \"\"\"Get all the checkpoints for the given configuration.\"\"\"\n",
    "        where, args = self._search_where(config, filter, before)\n",
    "        query = self.LIST_CHECKPOINTS_QUERY_STR.format(where=where)\n",
    "        if limit:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "                cur.execute(query, tuple(args))\n",
    "                for value in cur:\n",
    "                    checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    yield CheckpointTuple(\n",
    "                        config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        },\n",
    "                        checkpoint=self.serde.loads(checkpoint),\n",
    "                        metadata=self.serde.loads(metadata),\n",
    "                        parent_config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        }\n",
    "                        if parent_ts\n",
    "                        else None,\n",
    "                    )\n",
    "\n",
    "    async def alist(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        *,\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "        limit: Optional[int] = None,\n",
    "    ) -> AsyncIterator[CheckpointTuple]:\n",
    "        \"\"\"Get all the checkpoints for the given configuration.\"\"\"\n",
    "        where, args = self._search_where(config, filter, before)\n",
    "        query = self.LIST_CHECKPOINTS_QUERY_STR.format(where=where)\n",
    "        if limit:\n",
    "            query += f\" LIMIT {limit}\"\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "                await cur.execute(query, tuple(args))\n",
    "                async for value in cur:\n",
    "                    checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    yield CheckpointTuple(\n",
    "                        config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        },\n",
    "                        checkpoint=self.serde.loads(checkpoint),\n",
    "                        metadata=self.serde.loads(metadata),\n",
    "                        parent_config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        }\n",
    "                        if parent_ts\n",
    "                        else None,\n",
    "                    )\n",
    "\n",
    "    GET_CHECKPOINT_BY_TS_QUERY = \"\"\"\n",
    "    SELECT checkpoint, metadata, thread_ts, parent_ts\n",
    "    FROM checkpoints\n",
    "    WHERE thread_id = %(thread_id)s AND thread_ts = %(thread_ts)s\n",
    "    \"\"\"\n",
    "\n",
    "    GET_CHECKPOINT_QUERY = \"\"\"\n",
    "    SELECT checkpoint, metadata, thread_ts, parent_ts\n",
    "    FROM checkpoints\n",
    "    WHERE thread_id = %(thread_id)s\n",
    "    ORDER BY thread_ts DESC LIMIT 1\n",
    "    \"\"\"\n",
    "\n",
    "    def get_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get the checkpoint tuple for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "        Returns:\n",
    "            The checkpoint tuple for the given configuration if it exists,\n",
    "            otherwise None.\n",
    "            If thread_ts is None, the latest checkpoint is returned if it exists.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        with self._get_sync_connection() as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                # find the latest checkpoint for the thread_id\n",
    "                if thread_ts:\n",
    "                    cur.execute(\n",
    "                        self.GET_CHECKPOINT_BY_TS_QUERY,\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"thread_ts\": thread_ts,\n",
    "                        },\n",
    "                    )\n",
    "                else:\n",
    "                    cur.execute(\n",
    "                        self.GET_CHECKPOINT_QUERY,\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                        },\n",
    "                    )\n",
    "\n",
    "                # if a checkpoint is found, return it\n",
    "                if value := cur.fetchone():\n",
    "                    checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    if not config[\"configurable\"].get(\"thread_ts\"):\n",
    "                        config = {\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "                    # find any pending writes\n",
    "                    cur.execute(\n",
    "                        \"SELECT task_id, channel, value FROM writes WHERE thread_id = %(thread_id)s AND thread_ts = %(thread_ts)s\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"thread_ts\": thread_ts,\n",
    "                        },\n",
    "                    )\n",
    "                    # deserialize the checkpoint and metadata\n",
    "                    return CheckpointTuple(\n",
    "                        config=config,\n",
    "                        checkpoint=self.serde.loads(checkpoint),\n",
    "                        metadata=self.serde.loads(metadata),\n",
    "                        parent_config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": parent_ts,\n",
    "                            }\n",
    "                        }\n",
    "                        if parent_ts\n",
    "                        else None,\n",
    "#                        pending_writes=[\n",
    "#                            (task_id, channel, self.serde.loads(value))\n",
    "#                            for task_id, channel, value in cur\n",
    "#                        ]\n",
    "                    )\n",
    "\n",
    "    async def aget_tuple(self, config: RunnableConfig) -> Optional[CheckpointTuple]:\n",
    "        \"\"\"Get the checkpoint tuple for the given configuration.\n",
    "        Args:\n",
    "            config: The configuration for the checkpoint.\n",
    "                A dict with a `configurable` key which is a dict with\n",
    "                a `thread_id` key and an optional `thread_ts` key.\n",
    "                For example, { 'configurable': { 'thread_id': 'test_thread' } }\n",
    "        Returns:\n",
    "            The checkpoint tuple for the given configuration if it exists,\n",
    "            otherwise None.\n",
    "            If thread_ts is None, the latest checkpoint is returned if it exists.\n",
    "        \"\"\"\n",
    "        thread_id = config[\"configurable\"][\"thread_id\"]\n",
    "        thread_ts = config[\"configurable\"].get(\"thread_ts\")\n",
    "        async with self._get_async_connection() as conn:\n",
    "            async with conn.cursor() as cur:\n",
    "                # find the latest checkpoint for the thread_id\n",
    "                if thread_ts:\n",
    "                    await cur.execute(\n",
    "                        self.GET_CHECKPOINT_BY_TS_QUERY,\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"thread_ts\": thread_ts,\n",
    "                        },\n",
    "                    )\n",
    "                else:\n",
    "                    await cur.execute(\n",
    "                        self.GET_CHECKPOINT_QUERY,\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                        },\n",
    "                    )\n",
    "                # if a checkpoint is found, return it\n",
    "                if value := await cur.fetchone():\n",
    "                    checkpoint, metadata, thread_ts, parent_ts = value\n",
    "                    if not config[\"configurable\"].get(\"thread_ts\"):\n",
    "                        config = {\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": thread_ts,\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "                    # find any pending writes\n",
    "                    await cur.execute(\n",
    "                        \"SELECT task_id, channel, value FROM writes WHERE thread_id = %(thread_id)s AND thread_ts = %(thread_ts)s\",\n",
    "                        {\n",
    "                            \"thread_id\": thread_id,\n",
    "                            \"thread_ts\": thread_ts,\n",
    "                        },\n",
    "                    )\n",
    "                    # deserialize the checkpoint and metadata\n",
    "                    return CheckpointTuple(\n",
    "                        config=config,\n",
    "                        checkpoint=self.serde.loads(checkpoint),\n",
    "                        metadata=self.serde.loads(metadata),\n",
    "                        parent_config={\n",
    "                            \"configurable\": {\n",
    "                                \"thread_id\": thread_id,\n",
    "                                \"thread_ts\": parent_ts,\n",
    "                            }\n",
    "                        }\n",
    "                        if parent_ts\n",
    "                        else None,\n",
    "                        # pending_writes=[\n",
    "                        #    (task_id, channel, self.serde.loads(value))\n",
    "                        #    async for task_id, channel, value in cur\n",
    "                        #]\n",
    "                    )\n",
    "\n",
    "    def _search_where(\n",
    "        self,\n",
    "        config: Optional[RunnableConfig],\n",
    "        filter: Optional[dict[str, Any]] = None,\n",
    "        before: Optional[RunnableConfig] = None,\n",
    "    ) -> Tuple[str, List[Any]]:\n",
    "        \"\"\"Return WHERE clause predicates for given config, filter, and before parameters.\n",
    "        Args:\n",
    "            config (Optional[RunnableConfig]): The config to use for filtering.\n",
    "            filter (Optional[Dict[str, Any]]): Additional filtering criteria.\n",
    "            before (Optional[RunnableConfig]): A config to limit results before a certain timestamp.\n",
    "        Returns:\n",
    "            Tuple[str, Sequence[Any]]: A tuple containing the WHERE clause and parameter values.\n",
    "        \"\"\"\n",
    "        wheres = []\n",
    "        param_values = []\n",
    "\n",
    "        # Add predicate for config\n",
    "        if config is not None:\n",
    "            wheres.append(\"thread_id = %s \")\n",
    "            param_values.append(config[\"configurable\"][\"thread_id\"])\n",
    "\n",
    "        if filter:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "        # Add predicate for limiting results before a certain timestamp\n",
    "        if before is not None:\n",
    "            wheres.append(\"thread_ts < %s\")\n",
    "            param_values.append(before[\"configurable\"][\"thread_ts\"])\n",
    "\n",
    "        where_clause = \"WHERE \" + \" AND \".join(wheres) if wheres else \"\"\n",
    "        return where_clause, param_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../envls')\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_weather(city: Literal[\"nyc\", \"sf\"]):\n",
    "    \"\"\"Use this to get weather information.\"\"\"\n",
    "    if city == \"nyc\":\n",
    "        return \"It might be cloudy in nyc\"\n",
    "    elif city == \"sf\":\n",
    "        return \"It's always sunny in sf\"\n",
    "    else:\n",
    "        raise AssertionError(\"Unknown city\")\n",
    "\n",
    "\n",
    "tools = [get_weather]\n",
    "model = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DB_URI = \"postgresql://postgres:postgres@localhost:5432/postgres?sslmode=disable\"\n",
    "DB_URI = \"postgresql://postgres:repia@192.168.10.111:5432/postgres?sslmode=disable\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg_pool import ConnectionPool\n",
    "\n",
    "pool = ConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    ")\n",
    "\n",
    "checkpointer = PostgresSaver(sync_connection=pool)\n",
    "checkpointer.create_tables(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's the weather in sf\", id='7d43714e-503f-4c43-8149-bad6c7ee4036'),\n",
       "  AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TfGM9xmIrMjT6boJdPCnG92y', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f778edf3-9759-415e-b902-c9c653a8cfaa-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_TfGM9xmIrMjT6boJdPCnG92y', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),\n",
       "  ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='2516b088-00df-465a-9d8e-fac92449e987', tool_call_id='call_TfGM9xmIrMjT6boJdPCnG92y'),\n",
       "  AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-5cfb8529-0851-4e15-b1d7-90a517e879b0-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94}),\n",
       "  HumanMessage(content=\"what's the weather in sf\", id='0f24a100-80cb-4e71-9884-ae461485d398'),\n",
       "  AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 107, 'total_tokens': 117}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-d417e83c-d624-4a86-b356-313b5f1c1ef6-0', usage_metadata={'input_tokens': 107, 'output_tokens': 10, 'total_tokens': 117})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': 1,\n",
       " 'ts': '2024-07-18T08:31:27.147486+00:00',\n",
       " 'id': '1ef44e01-ff7d-6b1f-8006-1a3acfc7ec69',\n",
       " 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='7d43714e-503f-4c43-8149-bad6c7ee4036'),\n",
       "   AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_TfGM9xmIrMjT6boJdPCnG92y', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f778edf3-9759-415e-b902-c9c653a8cfaa-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_TfGM9xmIrMjT6boJdPCnG92y', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}),\n",
       "   ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='2516b088-00df-465a-9d8e-fac92449e987', tool_call_id='call_TfGM9xmIrMjT6boJdPCnG92y'),\n",
       "   AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-5cfb8529-0851-4e15-b1d7-90a517e879b0-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94}),\n",
       "   HumanMessage(content=\"what's the weather in sf\", id='0f24a100-80cb-4e71-9884-ae461485d398'),\n",
       "   AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 107, 'total_tokens': 117}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-d417e83c-d624-4a86-b356-313b5f1c1ef6-0', usage_metadata={'input_tokens': 107, 'output_tokens': 10, 'total_tokens': 117})],\n",
       "  'agent': 'agent'},\n",
       " 'channel_versions': {'__start__': 7,\n",
       "  'messages': 8,\n",
       "  'start:agent': 8,\n",
       "  'agent': 8,\n",
       "  'branch:agent:should_continue:tools': 4,\n",
       "  'tools': 5},\n",
       " 'versions_seen': {'__start__': {'__start__': 6},\n",
       "  'agent': {'start:agent': 7, 'tools': 5},\n",
       "  'tools': {'branch:agent:should_continue:tools': 3}},\n",
       " 'pending_sends': []}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer.get(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import Connection\n",
    "\n",
    "with Connection.connect(DB_URI) as conn:\n",
    "    checkpointer = PostgresSaver(sync_connection=conn)\n",
    "\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "    res = graph.invoke({\"messages\": [(\"human\", \"what's the weather in sf\")]}, config)\n",
    "\n",
    "    checkpoint_tuple = checkpointer.get_tuple(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jurepi/.pyenv/versions/langserve/lib/python3.11/site-packages/psycopg_pool/pool_async.py:138: RuntimeWarning: opening the async pool AsyncConnectionPool in the constructor is deprecated and will not be supported anymore in a future release. Please use `await pool.open()`, or use the pool as context manager using: `async with AsyncConnectionPool(...) as pool: `...\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from psycopg_pool import AsyncConnectionPool\n",
    "\n",
    "pool = AsyncConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    ")\n",
    "\n",
    "checkpointer = PostgresSaver(async_connection=pool)\n",
    "await checkpointer.acreate_tables(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "res = await graph.ainvoke(\n",
    "    {\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckpointTuple(config={'configurable': {'thread_id': '2', 'thread_ts': '1ef44e05-47ad-6180-8003-ff89a4b78c38'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:32:55.247286+00:00', 'id': '1ef44e05-47ad-6180-8003-ff89a4b78c38', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in sf\", id='ed1406ac-b338-4f6f-a123-612c45b12efb'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_ZeUAjQosItPGTQm7TdkbptZE', 'function': {'arguments': '{\"city\":\"sf\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 57, 'total_tokens': 71}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-24d9428f-26a7-4e18-86d2-fe38d900ec49-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'sf'}, 'id': 'call_ZeUAjQosItPGTQm7TdkbptZE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 57, 'output_tokens': 14, 'total_tokens': 71}), ToolMessage(content=\"It's always sunny in sf\", name='get_weather', id='d547a997-f07a-42f8-a944-520a554cb156', tool_call_id='call_ZeUAjQosItPGTQm7TdkbptZE'), AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-3eeed231-98d9-4755-acd0-9b56b2d25911-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__start__': {'__start__': 1}, 'agent': {'start:agent': 3, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 3, 'writes': {'agent': {'messages': [AIMessage(content='The weather in San Francisco is currently sunny.', response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-3eeed231-98d9-4755-acd0-9b56b2d25911-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}}}, parent_config={'configurable': {'thread_id': '2', 'thread_ts': '1ef44e05-318b-6121-8002-bc3244e7bc1a'}})\n"
     ]
    }
   ],
   "source": [
    "checkpoint_tuple\n",
    "\n",
    "print(checkpoint_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg import AsyncConnection\n",
    "\n",
    "async with await AsyncConnection.connect(DB_URI) as conn:\n",
    "    checkpointer = PostgresSaver(async_connection=conn)\n",
    "    graph = create_react_agent(model, tools=tools, checkpointer=checkpointer)\n",
    "    config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "    res = await graph.ainvoke(\n",
    "        {\"messages\": [(\"human\", \"what's the weather in nyc\")]}, config\n",
    "    )\n",
    "    checkpoint_tuples = [c async for c in checkpointer.alist(config)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-f7b4-61f6-8008-ca580f8dadd3'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:34:34.235739+00:00', 'id': '1ef44e08-f7b4-61f6-8008-ca580f8dadd3', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='5e6ac0e4-70b4-4702-b24b-3fe4b115fddc', tool_call_id='call_aEHYaumUeGI8wOcAYbEQucdJ'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'stop', 'logprobs': None}, id='run-2353e5be-389d-4d5a-a476-48fcdd41f177-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97}), HumanMessage(content=\"what's the weather in nyc\", id='eed9ce9f-7edb-4a15-bf00-fc53891edb78'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FRLGnYfkkyc05WOo7noKBx4G', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 111, 'total_tokens': 126}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b55b334d-8931-43cf-a399-78f8ca1030e7-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_FRLGnYfkkyc05WOo7noKBx4G', 'type': 'tool_call'}], usage_metadata={'input_tokens': 111, 'output_tokens': 15, 'total_tokens': 126}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='7b41fa83-9061-4a99-be6f-0e7461577bbe', tool_call_id='call_FRLGnYfkkyc05WOo7noKBx4G'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 141, 'total_tokens': 150}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-d22dc84a-cda5-435a-b4a5-eb45a72732c6-0', usage_metadata={'input_tokens': 141, 'output_tokens': 9, 'total_tokens': 150})], 'agent': 'agent'}, 'channel_versions': {'__start__': 7, 'messages': 10, 'start:agent': 8, 'agent': 10, 'branch:agent:should_continue:tools': 9, 'tools': 10}, 'versions_seen': {'__start__': {'__start__': 6}, 'agent': {'start:agent': 8, 'tools': 9}, 'tools': {'branch:agent:should_continue:tools': 8}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 8, 'writes': {'agent': {'messages': [AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 141, 'total_tokens': 150}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'stop', 'logprobs': None}, id='run-d22dc84a-cda5-435a-b4a5-eb45a72732c6-0', usage_metadata={'input_tokens': 141, 'output_tokens': 9, 'total_tokens': 150})]}}}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-f7b4-61f6-8008-ca580f8dadd3'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-edd3-6386-8007-74f3631339fc'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:34:33.199901+00:00', 'id': '1ef44e08-edd3-6386-8007-74f3631339fc', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='5e6ac0e4-70b4-4702-b24b-3fe4b115fddc', tool_call_id='call_aEHYaumUeGI8wOcAYbEQucdJ'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'stop', 'logprobs': None}, id='run-2353e5be-389d-4d5a-a476-48fcdd41f177-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97}), HumanMessage(content=\"what's the weather in nyc\", id='eed9ce9f-7edb-4a15-bf00-fc53891edb78'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FRLGnYfkkyc05WOo7noKBx4G', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 111, 'total_tokens': 126}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b55b334d-8931-43cf-a399-78f8ca1030e7-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_FRLGnYfkkyc05WOo7noKBx4G', 'type': 'tool_call'}], usage_metadata={'input_tokens': 111, 'output_tokens': 15, 'total_tokens': 126}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='7b41fa83-9061-4a99-be6f-0e7461577bbe', tool_call_id='call_FRLGnYfkkyc05WOo7noKBx4G')], 'tools': 'tools'}, 'channel_versions': {'__start__': 7, 'messages': 9, 'start:agent': 8, 'agent': 9, 'branch:agent:should_continue:tools': 9, 'tools': 9}, 'versions_seen': {'__start__': {'__start__': 6}, 'agent': {'start:agent': 7, 'tools': 5}, 'tools': {'branch:agent:should_continue:tools': 8}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 7, 'writes': {'tools': {'messages': [ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='7b41fa83-9061-4a99-be6f-0e7461577bbe', tool_call_id='call_FRLGnYfkkyc05WOo7noKBx4G')]}}}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-edd3-6386-8007-74f3631339fc'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-edca-65d4-8006-e156142fc762'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:34:33.196273+00:00', 'id': '1ef44e08-edca-65d4-8006-e156142fc762', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='5e6ac0e4-70b4-4702-b24b-3fe4b115fddc', tool_call_id='call_aEHYaumUeGI8wOcAYbEQucdJ'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'stop', 'logprobs': None}, id='run-2353e5be-389d-4d5a-a476-48fcdd41f177-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97}), HumanMessage(content=\"what's the weather in nyc\", id='eed9ce9f-7edb-4a15-bf00-fc53891edb78'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FRLGnYfkkyc05WOo7noKBx4G', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 111, 'total_tokens': 126}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b55b334d-8931-43cf-a399-78f8ca1030e7-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_FRLGnYfkkyc05WOo7noKBx4G', 'type': 'tool_call'}], usage_metadata={'input_tokens': 111, 'output_tokens': 15, 'total_tokens': 126})], 'agent': 'agent', 'branch:agent:should_continue:tools': 'agent'}, 'channel_versions': {'__start__': 7, 'messages': 8, 'start:agent': 8, 'agent': 8, 'branch:agent:should_continue:tools': 8, 'tools': 5}, 'versions_seen': {'__start__': {'__start__': 6}, 'agent': {'start:agent': 7, 'tools': 5}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 6, 'writes': {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FRLGnYfkkyc05WOo7noKBx4G', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 111, 'total_tokens': 126}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_c4e5b6fa31', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-b55b334d-8931-43cf-a399-78f8ca1030e7-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_FRLGnYfkkyc05WOo7noKBx4G', 'type': 'tool_call'}], usage_metadata={'input_tokens': 111, 'output_tokens': 15, 'total_tokens': 126})]}}}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-edca-65d4-8006-e156142fc762'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-e002-6bd6-8005-333c0103fe3e'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:34:31.751356+00:00', 'id': '1ef44e08-e002-6bd6-8005-333c0103fe3e', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='5e6ac0e4-70b4-4702-b24b-3fe4b115fddc', tool_call_id='call_aEHYaumUeGI8wOcAYbEQucdJ'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'stop', 'logprobs': None}, id='run-2353e5be-389d-4d5a-a476-48fcdd41f177-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97}), HumanMessage(content=\"what's the weather in nyc\", id='eed9ce9f-7edb-4a15-bf00-fc53891edb78')], 'start:agent': '__start__'}, 'channel_versions': {'__start__': 7, 'messages': 7, 'start:agent': 7, 'agent': 6, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__start__': {'__start__': 6}, 'agent': {'start:agent': 3, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 5, 'writes': None}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-e002-6bd6-8005-333c0103fe3e'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-dffe-67aa-8004-3b2139760c66'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:34:31.749610+00:00', 'id': '1ef44e08-dffe-67aa-8004-3b2139760c66', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='5e6ac0e4-70b4-4702-b24b-3fe4b115fddc', tool_call_id='call_aEHYaumUeGI8wOcAYbEQucdJ'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'stop', 'logprobs': None}, id='run-2353e5be-389d-4d5a-a476-48fcdd41f177-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})], '__start__': {'messages': [['human', \"what's the weather in nyc\"]]}}, 'channel_versions': {'__start__': 6, 'messages': 5, 'start:agent': 3, 'agent': 6, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__start__': {'__start__': 1}, 'agent': {'start:agent': 3, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'input', 'step': 4, 'writes': {'messages': [['human', \"what's the weather in nyc\"]]}}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44e08-dffe-67aa-8004-3b2139760c66'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-48ab-6de1-8003-c4ea7f987c78'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:18:36.358182+00:00', 'id': '1ef44de5-48ab-6de1-8003-c4ea7f987c78', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='5e6ac0e4-70b4-4702-b24b-3fe4b115fddc', tool_call_id='call_aEHYaumUeGI8wOcAYbEQucdJ'), AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'stop', 'logprobs': None}, id='run-2353e5be-389d-4d5a-a476-48fcdd41f177-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})], 'agent': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 5, 'start:agent': 3, 'agent': 5, 'branch:agent:should_continue:tools': 4, 'tools': 5}, 'versions_seen': {'__start__': {'__start__': 1}, 'agent': {'start:agent': 3, 'tools': 4}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 3, 'writes': {'agent': {'messages': [AIMessage(content='The weather in NYC might be cloudy.', response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 88, 'total_tokens': 97}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'stop', 'logprobs': None}, id='run-2353e5be-389d-4d5a-a476-48fcdd41f177-0', usage_metadata={'input_tokens': 88, 'output_tokens': 9, 'total_tokens': 97})]}}}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-48ab-6de1-8003-c4ea7f987c78'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-3fa8-6aa2-8002-16419a7a2f3d'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:18:35.413150+00:00', 'id': '1ef44de5-3fa8-6aa2-8002-16419a7a2f3d', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73}), ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='5e6ac0e4-70b4-4702-b24b-3fe4b115fddc', tool_call_id='call_aEHYaumUeGI8wOcAYbEQucdJ')], 'tools': 'tools'}, 'channel_versions': {'__start__': 2, 'messages': 4, 'start:agent': 3, 'agent': 4, 'branch:agent:should_continue:tools': 4, 'tools': 4}, 'versions_seen': {'__start__': {'__start__': 1}, 'agent': {'start:agent': 2}, 'tools': {'branch:agent:should_continue:tools': 3}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 2, 'writes': {'tools': {'messages': [ToolMessage(content='It might be cloudy in nyc', name='get_weather', id='5e6ac0e4-70b4-4702-b24b-3fe4b115fddc', tool_call_id='call_aEHYaumUeGI8wOcAYbEQucdJ')]}}}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-3fa8-6aa2-8002-16419a7a2f3d'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-3f9f-60ed-8001-5cb13ae9c191'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:18:35.409215+00:00', 'id': '1ef44de5-3f9f-60ed-8001-5cb13ae9c191', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73})], 'agent': 'agent', 'branch:agent:should_continue:tools': 'agent'}, 'channel_versions': {'__start__': 2, 'messages': 3, 'start:agent': 3, 'agent': 3, 'branch:agent:should_continue:tools': 3}, 'versions_seen': {'__start__': {'__start__': 1}, 'agent': {'start:agent': 2}, 'tools': {}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 1, 'writes': {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'function': {'arguments': '{\"city\":\"nyc\"}', 'name': 'get_weather'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 58, 'total_tokens': 73}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_5e997b69d8', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-f41acf21-fc8a-4007-bebb-760620a35248-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'nyc'}, 'id': 'call_aEHYaumUeGI8wOcAYbEQucdJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 58, 'output_tokens': 15, 'total_tokens': 73})]}}}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-3f9f-60ed-8001-5cb13ae9c191'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-3703-6139-8000-7204cdce7e6e'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:18:34.506462+00:00', 'id': '1ef44de5-3703-6139-8000-7204cdce7e6e', 'channel_values': {'messages': [HumanMessage(content=\"what's the weather in nyc\", id='39ddbf6c-3db1-4cba-9ac5-51c527815e15')], 'start:agent': '__start__'}, 'channel_versions': {'__start__': 2, 'messages': 2, 'start:agent': 2}, 'versions_seen': {'__start__': {'__start__': 1}, 'agent': {}, 'tools': {}}, 'pending_sends': []}, metadata={'source': 'loop', 'step': 0, 'writes': None}, parent_config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-3703-6139-8000-7204cdce7e6e'}}), CheckpointTuple(config={'configurable': {'thread_id': '4', 'thread_ts': '1ef44de5-36fe-67bc-bfff-a79a41d256ee'}}, checkpoint={'v': 1, 'ts': '2024-07-18T08:18:34.504585+00:00', 'id': '1ef44de5-36fe-67bc-bfff-a79a41d256ee', 'channel_values': {'messages': [], '__start__': {'messages': [['human', \"what's the weather in nyc\"]]}}, 'channel_versions': {'__start__': 1}, 'versions_seen': {}, 'pending_sends': []}, metadata={'source': 'input', 'step': -1, 'writes': {'messages': [['human', \"what's the weather in nyc\"]]}}, parent_config=None)]\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langserve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
